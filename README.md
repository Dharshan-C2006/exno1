# Exno:1
Data Cleaning Process

# AIM
To read the given data and perform data cleaning and save the cleaned data to a file.

# Explanation
Data cleaning is the process of preparing data for analysis by removing or modifying data that is incorrect ,incompleted , irrelevant , duplicated or improperly formatted. Data cleaning is not simply about erasing data ,but rather finding a way to maximize datasets accuracy without necessarily deleting the information.

# Algorithm
STEP 1: Read the given Data

STEP 2: Get the information about the data

STEP 3: Remove the null values from the data

STEP 4: Save the Clean data to the file

STEP 5: Remove outliers using IQR

STEP 6: Use zscore of to remove outliers

# Coding and Output

![Screenshot 2024-10-18 130046](https://github.com/user-attachments/assets/44777d95-0cbb-450b-aadf-85cb8a67f4ad)
![Screenshot 2024-10-18 130057](https://github.com/user-attachments/assets/df060711-92b7-4d8c-abb9-7d8d14f56187)
![Screenshot 2024-10-18 131821](https://github.com/user-attachments/assets/408e9eef-e70c-417b-b814-0f79f32347)
![Screenshot 2024-10-18 131832](https://github.com/user-attachments/assets/2b2f925f-c6bd-4817-ada3-fb91b21cf555)
![Screenshot 2024-10-18 131842](https://github.com/user-attachments/assets/e2736b42-7a55-46ab-9028-f9b9d714e029)
![Screenshot 2024-10-18 131852](https://github.com/user-attachments/assets/ae247fb8-e550-4d96-bb0d-ef95b7e2fac8)
![Screenshot 2024-10-18 131903](https://github.com/user-attachments/assets/18da9741-d258-4410-80c3-6bafa90ca5a7)
![Screenshot 2024-10-18 131912](https://github.com/user-attachments/assets/7e93d588-ed8b-4547-a2a5-6271f269a57a)
![Screenshot 2024-10-21 114139](https://github.com/user-attachments/assets/beba9b64-ccdd-4a56-b57a-e9ca3517fb80)
![Screenshot 2024-10-21 114154](https://github.com/user-attachments/assets/6959ce32-74ec-4e5b-be51-ed8ee731517a)

![Screenshot 2024-10-21 114456](https://github.com/user-attachments/assets/7714aa95-40f4-48b3-bf47-ba0b00ad3259)
![Screenshot 2024-10-21 114506](https://github.com/user-attachments/assets/2c1cf49b-6727-4bd6-b430-063c1080d137)

![Screenshot 2024-10-21 114517](https://github.com/user-attachments/assets/a4e09749-22f8-4c9d-826c-f
![Screenshot 2024-10-21 114528](https://github.com/user-attachments/assets/86e53558-b022-4c95-9ddf-08068622aa48)
ac6755cd
![Screenshot 2024-10-21 114541](https://github.com/user-attachments/assets/1f3f4e78-c23c-4551-a875-a921c10c6455)
ed1)

![Screenshot 2024-10-21 114552](https://github.com/user-attachments/assets/4ea5faee-8108-428f-8135-9ab6e59a81a7)
![Screenshot 2024-10-21 114603](https://github.com/user-attachments/assets/a5ddcc28-db3b-49a1-af94-1660ed965008)
![Screenshot 2024-10-21 114612](https://github.com/user-attachments/assets/2caa8967-e918-43ab-86c2-3d5e7fc9f1d6)

![Screenshot 2024-10-21 114624](https://github.com/user-attachments/assets/91735d5f-01c5-4f34-9210-8735980aaec6)

![Screenshot 2024-10-21 114634](https://github.com/user-attachments/assets/6ddb26ff-f707-4400-85aa-83f0912d6f71)

# Result

Thus we have read and cleaned the data and also removed the outliers by detection using IQR and Z-score method.
